{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this notebook, we will perform Exploratory Data Analysis (EDA) on the dataset obtained from [Luke Barousse's Hugging Face repository](https://huggingface.co/lukebarousse). The goal of this notebook is to clean and prepare the data for further analysis, focusing on data jobs. We will filter the dataset for Pakistan and a set of comparison countries, then save the results to CSV files for further analysis.\n",
    "\n",
    "## Steps:\n",
    "1. Import the dataset.\n",
    "2. Clean the data by removing duplicates and filtering for data-related jobs.\n",
    "3. Prepare two subsets of the data:\n",
    "   - Jobs in Pakistan\n",
    "   - Jobs in comparison countries (Turkey, Bangladesh, Nigeria, Egypt)\n",
    "4. Save the cleaned datasets to CSV files for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3         Data Engineer  LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4         Data Engineer                             Data Engineer- Sr Jobs   \n",
       "\n",
       "                   job_location             job_via job_schedule_type  \\\n",
       "0                 Watertown, CT     via Work Nearby         Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico    via BeBee México         Full-time   \n",
       "2               Berlin, Germany        via LinkedIn         Full-time   \n",
       "3               San Antonio, TX   via Diversity.com         Full-time   \n",
       "4                Washington, DC  via Clearance Jobs         Full-time   \n",
       "\n",
       "   job_work_from_home       search_location      job_posted_date  \\\n",
       "0               False  Texas, United States  2023-06-16 13:44:15   \n",
       "1               False                Mexico  2023-01-14 13:18:07   \n",
       "2               False               Germany  2023-10-10 13:14:55   \n",
       "3               False  Texas, United States  2023-07-04 13:01:41   \n",
       "4               False                 Sudan  2023-08-07 14:29:36   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States        None   \n",
       "1                  False                 False         Mexico        None   \n",
       "2                  False                 False        Germany        None   \n",
       "3                   True                 False  United States        None   \n",
       "4                  False                 False          Sudan        None   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                  company_name  \\\n",
       "0              NaN              NaN          Boehringer Ingelheim   \n",
       "1              NaN              NaN    Hewlett Packard Enterprise   \n",
       "2              NaN              NaN      ALPHA Augmented Services   \n",
       "3              NaN              NaN  Southwest Research Institute   \n",
       "4              NaN              NaN               Kristina Daniel   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                               None   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3  ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4  ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                               None  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3  {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4  {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# get the required dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a regular expression pattern to match \"Data\", \"Analyst\", or \"Machine Learning\" in job titles\n",
    "pattern = r'(Data|Analyst|Machine Learning)'\n",
    "\n",
    "# Filter the DataFrame based on 'job_title_short' containing 'Data', 'Analyst', or 'Machine Learning'\n",
    "df = df[df['job_title_short'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Check the result\n",
    "df.job_title_short.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title_short           object\n",
       "job_title                 object\n",
       "job_location              object\n",
       "job_via                   object\n",
       "job_schedule_type         object\n",
       "job_work_from_home          bool\n",
       "search_location           object\n",
       "job_posted_date           object\n",
       "job_no_degree_mention       bool\n",
       "job_health_insurance        bool\n",
       "job_country               object\n",
       "salary_rate               object\n",
       "salary_year_avg          float64\n",
       "salary_hour_avg          float64\n",
       "company_name              object\n",
       "job_skills                object\n",
       "job_type_skills           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'NoneType'>, <class 'list'>], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_types = df['job_skills'].apply(type).unique()\n",
    "unique_types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "job skills is showm as object(STRING) but it contains multiple skills and can be converted to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        785741 non-null  object \n",
      " 1   job_title              785740 non-null  object \n",
      " 2   job_location           784696 non-null  object \n",
      " 3   job_via                785733 non-null  object \n",
      " 4   job_schedule_type      773074 non-null  object \n",
      " 5   job_work_from_home     785741 non-null  bool   \n",
      " 6   search_location        785741 non-null  object \n",
      " 7   job_posted_date        785741 non-null  object \n",
      " 8   job_no_degree_mention  785741 non-null  bool   \n",
      " 9   job_health_insurance   785741 non-null  bool   \n",
      " 10  job_country            785692 non-null  object \n",
      " 11  salary_rate            33067 non-null   object \n",
      " 12  salary_year_avg        22003 non-null   float64\n",
      " 13  salary_hour_avg        10662 non-null   float64\n",
      " 14  company_name           785723 non-null  object \n",
      " 15  job_skills             668704 non-null  object \n",
      " 16  job_type_skills        668704 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#cleaning data\n",
    "import ast\n",
    "def convert_job_skills(x):\n",
    "    '''Convert string to list'''\n",
    "    try:\n",
    "        if pd.notna(x):\n",
    "            return ast.literal_eval(x)\n",
    "        else:\n",
    "            return x\n",
    "    except (ValueError, SyntaxError):\n",
    "        return x\n",
    "\n",
    "df['job_skills'] = df['job_skills'].apply(convert_job_skills)\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 101 duplicated rows in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job_title_short               0\n",
       "job_title                     1\n",
       "job_location               1045\n",
       "job_via                       8\n",
       "job_schedule_type         12667\n",
       "job_work_from_home            0\n",
       "search_location               0\n",
       "job_posted_date               0\n",
       "job_no_degree_mention         0\n",
       "job_health_insurance          0\n",
       "job_country                  49\n",
       "salary_rate              752674\n",
       "salary_year_avg          763738\n",
       "salary_hour_avg          775079\n",
       "company_name                 18\n",
       "job_skills               117037\n",
       "job_type_skills          117037\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_rows=df.duplicated().sum()\n",
    "print(f\"There are {duplicated_rows} duplicated rows in the dataset.\")\n",
    "\n",
    "df.isna().sum()\n",
    "df= df.dropna(subset=['job_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 277699 duplicated job posting in multiple sites\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#handling same job posted on multiple sites\n",
    "length_df=len(df)\n",
    "lenght_spam_removed_df=len(df.drop_duplicates(subset=['job_title','company_name']))\n",
    "print('There are',length_df-lenght_spam_removed_df, 'duplicated job posting in multiple sites')\n",
    "df=df.drop_duplicates(subset=['job_title','company_name'])\n",
    "#only look for jobs where jobs are realated to data\n",
    "df.job_title_short.unique()\n",
    "\n",
    "# Convert 'job_posted_date' column to datetime\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4957</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2023-07-13 08:51:18.607423744</td>\n",
       "      <td>83251.860465</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-01-01 00:03:34</td>\n",
       "      <td>16500.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-03-30 16:22:21</td>\n",
       "      <td>63900.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2023-07-29 03:31:41</td>\n",
       "      <td>79200.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-10-25 11:35:27</td>\n",
       "      <td>99575.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-12-31 17:27:59</td>\n",
       "      <td>166419.500000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32029.497545</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     job_posted_date  salary_year_avg  salary_hour_avg\n",
       "count                           4957        43.000000              1.0\n",
       "mean   2023-07-13 08:51:18.607423744     83251.860465             15.0\n",
       "min              2023-01-01 00:03:34     16500.000000             15.0\n",
       "25%              2023-03-30 16:22:21     63900.000000             15.0\n",
       "50%              2023-07-29 03:31:41     79200.000000             15.0\n",
       "75%              2023-10-25 11:35:27     99575.000000             15.0\n",
       "max              2023-12-31 17:27:59    166419.500000             15.0\n",
       "std                              NaN     32029.497545              NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics for Comparison Countries:\n",
      "            salary_year_avg          job_title_short\n",
      "                       mean      std           count\n",
      "job_country                                         \n",
      "Bangladesh          42750.0  37123.0             186\n",
      "Egypt               75847.4  19420.0            1794\n",
      "Nigeria            100741.1  34693.0             703\n",
      "Pakistan            69287.5  27970.0            1371\n",
      "Turkey              94692.6  32394.0             903\n",
      "Cleaned DataFrame for comparison countries saved to 'df_comparison_countries.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Define the countries for comparison\n",
    "comparison_countries = ['Pakistan', 'Turkey', 'Bangladesh', 'Nigeria', 'Egypt']\n",
    "\n",
    "# Filter the DataFrame for these countries\n",
    "df_comparison_countries = df[df['job_country'].isin(comparison_countries)]\n",
    "\n",
    "# Display basic statistics for the selected countries\n",
    "print(\"Basic Statistics for Comparison Countries:\")\n",
    "country_salary_stats = df_comparison_countries.groupby('job_country').agg({\n",
    "    'salary_year_avg': ['mean', 'std'],\n",
    "    'job_title_short': 'count'\n",
    "})\n",
    "# Rounding 'mean' and 'std' columns for 'salary_year_avg'\n",
    "country_salary_stats[('salary_year_avg', 'mean')] = country_salary_stats[('salary_year_avg', 'mean')].round(1)\n",
    "country_salary_stats[('salary_year_avg', 'std')] = country_salary_stats[('salary_year_avg', 'std')].round()\n",
    "\n",
    "print(country_salary_stats)\n",
    "\n",
    "# Save the cleaned DataFrame for comparison countries\n",
    "df_comparison_countries.to_csv('df_comparison_countries.csv', index=False, header=True)\n",
    "\n",
    "print(f\"Cleaned DataFrame for comparison countries saved to 'df_comparison_countries.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection (example for salary)\n",
    "q1 = df['salary_year_avg'].quantile(0.25)\n",
    "q3 = df['salary_year_avg'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "df_filtered = df[(df['salary_year_avg'] >= lower_bound) & (df['salary_year_avg'] <= upper_bound)]\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='job_country', y='salary_year_avg', data=df_filtered, palette='viridis')\n",
    "plt.title('Boxplot of Annual Salaries by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Annual Salary (Average)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for Pakistan\n",
    "df_pakistan = df[df['job_country'] == 'Pakistan']\n",
    "# Save the cleaned DataFrame for Pakistan\n",
    "df_pakistan.to_csv('df_pak.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title_short             0\n",
       "job_title                   0\n",
       "job_location                0\n",
       "job_via                     0\n",
       "job_schedule_type           7\n",
       "job_work_from_home          0\n",
       "search_location             0\n",
       "job_posted_date             0\n",
       "job_no_degree_mention       0\n",
       "job_health_insurance        0\n",
       "job_country                 0\n",
       "salary_rate              4907\n",
       "salary_year_avg          4914\n",
       "salary_hour_avg          4956\n",
       "company_name                1\n",
       "job_skills                879\n",
       "job_type_skills           879\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
